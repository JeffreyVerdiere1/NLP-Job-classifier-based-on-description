{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lstm_pipeline.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNyFVDvbs4iqDJsnwZk/KA3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"d0pDRySinsay"},"outputs":[],"source":["!git lfs install\n","!git clone https://huggingface.co/oscarfossey/job_classification\n","!pip install pickle\n","!pip install spacy\n","!spacy download fr_core_news_sm\n","!pip install joblib"]},{"cell_type":"code","source":["import numpy as np\n","import nltk\n","import spacy\n","import pickle\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","nltk.download('stopwords')\n","\n","global LSTM_tokenizer, stopwords, nlp\n","\n","stopwords = nltk.corpus.stopwords.words('french')\n","nlp = spacy.load(\"fr_core_news_sm\")\n","LSTM_tokenizer = pickle.load(open(\"/content/job_classification/LSTM_tokenizer\", 'rb'))\n","\n","def preprocessing_LSTM(texts_array):\n","    \"\"\"preprocessing the strings through the array to predict using the predict_tfidf function\n","    return an array of token inputs\"\"\"\n","    \n","    init_shape  = texts_array.shape\n","    \n","    def preprocess(text):\n","      text = text.lower()\n","      text = text.replace('(', ' ').replace(')', ' ').replace('.', ' ').replace('  ', ' ')  #drop '(', ')', '.'\n","      text = nlp(text)\n","      words = [token.lemma_ for sent in text.sents for token in sent if not token.text in set(stopwords)]\n","      string = ' '.join(words)\n","      return string\n","\n","    def tokenization_LSTM(new_offer):\n","\n","      MAX_SEQUENCE_LENGTH=250\n","      MAX_NB_WORDS = 50000\n","      seq = LSTM_tokenizer.texts_to_sequences([preprocess(new_offer)])\n","      padded = pad_sequences(seq, maxlen = MAX_SEQUENCE_LENGTH)\n","      \n","      return (padded)\n","\n","    token_inputs = np.array([tokenization_LSTM(preprocess(txt)) for txt in list(texts_array.flatten())])\n","\n","    return token_inputs"],"metadata":{"id":"evLS2NaunzfX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from joblib import load\n","import numpy as np\n","\n","global lstm_model\n","lstm_model = load(open(\"/content/job_classification/model_LSTM.joblib\", 'rb')) \n","\n","def predict_LSTM(texts_array):\n","  \n","  init_shape  = texts_array.shape\n","\n","  predictions = np.array([lstm_model.predict(token_input)  for token_input in list(preprocessing_LSTM(texts_array.flatten()))])\n","  labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'N', 'M']\n","  predictions = np.array([labels[np.argmax(pred)] for pred in predictions])\n","  \n","  return predictions.reshape(init_shape)"],"metadata":{"id":"wcPtra6kn2xL"},"execution_count":null,"outputs":[]}]}